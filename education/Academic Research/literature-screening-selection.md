---
title: Literature Screening and Selection
category: education/Academic Research
tags: [communication, education, research, strategy, template, testing]
use_cases:
  - Screening studies identified through systematic searches using inclusion and exclusion criteria
  - Following PRISMA methodology for transparent selection processes in systematic reviews
  - Conducting multi-stage screening with quality assessment and bias risk evaluation
related_templates:
  - literature-reviews-overview.md
  - literature-search-strategy.md
  - literature-synthesis-analysis.md
  - systematic-review-writing.md
  - citation-reference-management.md
last_updated: 2025-11-09
---

# Literature Screening and Selection

## Purpose
Create systematic, transparent, and reproducible processes for screening and selecting studies in literature reviews. This template guides multi-stage screening procedures, application of inclusion/exclusion criteria, PRISMA flow diagram development, quality assessment, and data extraction to ensure methodological rigor and minimize bias.

## Template

```
You are an expert systematic review methodologist with extensive experience in study selection, quality assessment, bias evaluation, screening procedures, and PRISMA methodology. Create a detailed study screening and selection protocol based on the following information:

Research Context:
- Research Topic: [RESEARCH_TOPIC]
- Review Type: [REVIEW_METHODOLOGY]
- Research Question: [MAIN_RESEARCH_QUESTION]
- Total Records Identified: [INITIAL_RECORDS_COUNT]

### Selection Criteria Overview
- Publication Period: [START_DATE] to [END_DATE]
- Study Designs: [ACCEPTABLE_STUDY_DESIGNS]
- Population Focus: [TARGET_POPULATION]
- Geographic Scope: [GEOGRAPHIC_LIMITS]
- Language Restrictions: [LANGUAGE_CRITERIA]

Generate a comprehensive screening and selection protocol that includes:

## 1. INCLUSION AND EXCLUSION CRITERIA

### 1.1 Inclusion Criteria Framework

#### Population Criteria
Included populations:
- Age range: [AGE_RANGE]
- Demographics: [DEMOGRAPHIC_CHARACTERISTICS]
- Health status: [HEALTH_STATUS_CRITERIA]
- Setting: [SETTING_REQUIREMENTS]
- Specific characteristics: [POPULATION_SPECIFIC_FEATURES]

Rationale for population criteria:
- Alignment with research question: [POPULATION_JUSTIFICATION]
- Generalizability considerations: [GENERALIZABILITY_RATIONALE]
- Practical relevance: [PRACTICAL_SIGNIFICANCE]

#### Study Design Criteria
Included study designs:
- Experimental designs:
  * Randomized controlled trials (RCTs)
  * Cluster randomized trials
  * Quasi-experimental designs
  * [EXPERIMENTAL_DESIGN_1]

- Observational designs:
  * Cohort studies (prospective/retrospective)
  * Case-control studies
  * Cross-sectional studies
  * [OBSERVATIONAL_DESIGN_1]

- Qualitative designs:
  * Phenomenological studies
  * Grounded theory
  * Ethnographic studies
  * [QUALITATIVE_DESIGN_1]

- Mixed-methods designs:
  * [MIXED_METHOD_DESIGN_1]
  * [MIXED_METHOD_DESIGN_2]

Design inclusion rationale:
- Methodological appropriateness: [DESIGN_JUSTIFICATION]
- Evidence hierarchy considerations: [HIERARCHY_RATIONALE]

#### Intervention/Exposure Criteria
Included interventions:
- Intervention type: [INTERVENTION_TYPES]
- Intervention components: [INTERVENTION_COMPONENTS]
- Delivery methods: [DELIVERY_MODES]
- Duration requirements: [DURATION_CRITERIA]
- Intensity requirements: [INTENSITY_CRITERIA]
- Provider qualifications: [PROVIDER_REQUIREMENTS]

Included exposures (for observational studies):
- Exposure definition: [EXPOSURE_DEFINITION]
- Exposure measurement: [EXPOSURE_ASSESSMENT]
- Exposure timing: [TEMPORAL_REQUIREMENTS]

#### Comparison/Control Criteria
Acceptable comparison conditions:
- Active control: [ACTIVE_CONTROL_TYPES]
- Usual care/standard treatment: [STANDARD_CARE_DEFINITION]
- Waitlist control: [WAITLIST_CRITERIA]
- Placebo: [PLACEBO_SPECIFICATIONS]
- No treatment: [NO_TREATMENT_CONDITIONS]
- Different exposure levels: [EXPOSURE_COMPARISONS]

#### Outcome Criteria
Primary outcomes required:
- Outcome 1: [PRIMARY_OUTCOME_1]
  * Definition: [OUTCOME_1_DEFINITION]
  * Measurement: [OUTCOME_1_MEASUREMENT]
  * Timing: [OUTCOME_1_TIMING]

- Outcome 2: [PRIMARY_OUTCOME_2]
  * Definition: [OUTCOME_2_DEFINITION]
  * Measurement: [OUTCOME_2_MEASUREMENT]

Secondary outcomes considered:
- [SECONDARY_OUTCOME_1]
- [SECONDARY_OUTCOME_2]
- [SECONDARY_OUTCOME_3]

Outcome measurement requirements:
- Validated instruments: [INSTRUMENT_REQUIREMENTS]
- Minimum follow-up: [FOLLOWUP_DURATION]
- Objective vs. subjective measures: [MEASUREMENT_TYPE_CRITERIA]

#### Publication Criteria
Included publication types:
- Peer-reviewed journal articles
- Conference proceedings: [CONFERENCE_CRITERIA]
- Dissertations/theses: [THESIS_CRITERIA]
- Government reports: [REPORT_CRITERIA]
- Grey literature: [GREY_LITERATURE_TYPES]

Publication status:
- Published studies
- In-press articles: [IN_PRESS_CRITERIA]
- Unpublished data: [UNPUBLISHED_CRITERIA]

Language criteria:
- Primary languages: [PRIMARY_LANGUAGES]
- Additional languages with translation: [SECONDARY_LANGUAGES]
- Language exclusion justification: [LANGUAGE_JUSTIFICATION]

### 1.2 Exclusion Criteria Framework

#### Population Exclusions
Excluded populations:
- Age restrictions: [EXCLUDED_AGE_GROUPS]
- Animal studies: [ANIMAL_STUDY_POLICY]
- Specific conditions: [EXCLUDED_CONDITIONS]
- Settings: [EXCLUDED_SETTINGS]
- Rationale: [POPULATION_EXCLUSION_RATIONALE]

#### Design Exclusions
Excluded study types:
- Case reports and case series: [CASE_STUDY_POLICY]
- Editorials and commentaries
- Letters to the editor
- Opinion pieces
- Narrative reviews without systematic methods
- [EXCLUDED_DESIGN_1]

Rationale for design exclusions:
- Evidence quality concerns: [QUALITY_RATIONALE]
- Methodological limitations: [METHOD_LIMITATIONS]

#### Intervention/Exposure Exclusions
Excluded interventions:
- Intervention characteristic 1: [EXCLUDED_INTERVENTION_1]
- Intervention characteristic 2: [EXCLUDED_INTERVENTION_2]
- Insufficient description: [DESCRIPTION_REQUIREMENTS]
- Inappropriate comparisons: [COMPARISON_EXCLUSIONS]

#### Publication Exclusions
Excluded publication types:
- Abstracts only: [ABSTRACT_ONLY_POLICY]
- Conference posters: [POSTER_POLICY]
- Protocol papers: [PROTOCOL_POLICY]
- Retracted articles
- Duplicate publications: [DUPLICATE_HANDLING]

#### Quality-Based Exclusions
Minimum quality thresholds:
- Sample size: [MINIMUM_SAMPLE_SIZE]
- Attrition rate: [MAXIMUM_ATTRITION]
- Risk of bias: [BIAS_THRESHOLD]
- Reporting quality: [REPORTING_STANDARDS]

### 1.3 Criteria Application Guidelines

#### Ambiguous Cases
Decision-making framework:
- Consultation process: [CONSULTATION_APPROACH]
- Tie-breaking procedures: [TIEBREAKER_METHOD]
- Documentation requirements: [DOCUMENTATION_STANDARD]
- Default approach: [DEFAULT_DECISION_RULE]

#### Borderline Studies
Handling strategy:
- Initial inclusion for full review: [BORDERLINE_STRATEGY]
- Additional information seeking: [INFORMATION_REQUEST_PROCESS]
- Expert consultation: [EXPERT_INPUT_PROTOCOL]

## 2. SCREENING PROCESS AND PROCEDURES

### 2.1 Multi-Stage Screening Protocol

#### Stage 1: De-duplication
De-duplication procedures:
- Software tools: [DEDUPLICATION_SOFTWARE]
- Automated de-duplication: [AUTOMATED_METHODS]
- Manual verification: [MANUAL_CHECKING]
- Near-duplicate identification: [NEAR_DUPLICATE_APPROACH]
- Documentation: [DUPLICATE_TRACKING]

De-duplication criteria:
- Matching fields: [MATCHING_CRITERIA]
- Sensitivity level: [MATCHING_SENSITIVITY]
- Manual review triggers: [REVIEW_TRIGGERS]

#### Stage 2: Title and Abstract Screening
Screening approach:
- Reviewer assignment: [REVIEWER_ROLES]
  * Single reviewer screening: [SINGLE_SCREENING_SCOPE]
  * Dual reviewer screening: [DUAL_SCREENING_SCOPE]
  * Triple reviewer for conflicts: [CONFLICT_RESOLUTION]

Screening software:
- Platform: [SCREENING_SOFTWARE]
- Training completion: [REVIEWER_TRAINING]
- Pilot screening: [PILOT_SAMPLE_SIZE]
- Inter-rater reliability target: [RELIABILITY_TARGET]

Screening procedure:
1. Review title for obvious exclusions
2. Review abstract against inclusion criteria
3. Default to inclusion when uncertain
4. Flag for full-text review if any criterion met
5. Document exclusion reasons

Decision categories:
- Include (proceed to full-text)
- Exclude (document reason)
- Uncertain (default to inclusion)

#### Stage 3: Full-Text Review
Full-text screening protocol:
- Reviewer assignment: [FULLTEXT_REVIEWER_ASSIGNMENT]
- Independent dual review: [DUAL_REVIEW_PROPORTION]
- Consensus procedures: [CONSENSUS_APPROACH]
- Third reviewer arbitration: [ARBITRATION_PROCESS]

Full-text assessment criteria:
- Detailed criteria application: [DETAILED_CRITERIA_CHECKLIST]
- Multiple criteria verification: [VERIFICATION_APPROACH]
- Data extraction pilot: [PILOT_EXTRACTION]

Document retrieval:
- Full-text access methods: [ACCESS_STRATEGIES]
- Interlibrary loan: [ILL_PROCEDURES]
- Author contact: [AUTHOR_REQUEST_PROTOCOL]
- Timing: [RETRIEVAL_TIMELINE]
- Unavailable full-text handling: [UNAVAILABLE_PROTOCOL]

#### Stage 4: Final Inclusion Determination
Final verification:
- Criteria checklist completion: [FINAL_CHECKLIST]
- Data availability verification: [DATA_COMPLETENESS_CHECK]
- Quality threshold confirmation: [QUALITY_VERIFICATION]
- Duplicate publication check: [FINAL_DUPLICATE_CHECK]

### 2.2 Reviewer Management and Training

#### Reviewer Selection and Assignment
Reviewer qualifications:
- Content expertise: [CONTENT_REQUIREMENTS]
- Methodological training: [METHOD_REQUIREMENTS]
- Previous review experience: [EXPERIENCE_REQUIREMENTS]
- Language capabilities: [LANGUAGE_SKILLS]

Team composition:
- Primary reviewers: [PRIMARY_REVIEWER_COUNT]
- Secondary reviewers: [SECONDARY_REVIEWER_COUNT]
- Content experts: [EXPERT_CONSULTANT_COUNT]
- Methodological experts: [METHODOLOGY_CONSULTANT_COUNT]

#### Reviewer Training Protocol
Training components:
1. Review protocol overview and objectives
2. Inclusion/exclusion criteria detailed review
3. Screening software training and practice
4. Pilot screening with discussion
5. Disagreement resolution procedures
6. Documentation standards
7. Timeline and expectations

Training materials:
- Protocol document: [PROTOCOL_ACCESS]
- Criteria decision tree: [DECISION_TREE_TOOL]
- Example studies: [TRAINING_EXAMPLES]
- Screening manual: [MANUAL_REFERENCE]

#### Pilot Screening and Calibration
Pilot sample:
- Sample size: [PILOT_SIZE]
- Sample selection: [PILOT_SELECTION_METHOD]
- Diversity of studies: [PILOT_DIVERSITY]

Calibration process:
- Independent pilot screening: [PILOT_PROCEDURE]
- Inter-rater agreement calculation: [AGREEMENT_METRIC]
- Target agreement level: [TARGET_KAPPA]
- Disagreement discussion: [CALIBRATION_DISCUSSION]
- Criteria clarification: [CLARIFICATION_PROCESS]
- Re-piloting if needed: [REPEAT_PILOT_CRITERIA]

### 2.3 Disagreement Resolution

#### Conflict Identification
Agreement tracking:
- Agreement metrics: [AGREEMENT_TRACKING]
- Disagreement patterns: [PATTERN_ANALYSIS]
- Systematic differences: [SYSTEMATIC_REVIEW]

#### Resolution Procedures
Step 1: Discussion between reviewers
- Discussion format: [DISCUSSION_APPROACH]
- Criteria re-examination: [CRITERIA_REVIEW]
- Evidence presentation: [EVIDENCE_SHARING]
- Consensus attempt: [CONSENSUS_PROCESS]

Step 2: Third reviewer arbitration
- Arbitrator selection: [ARBITRATOR_CRITERIA]
- Information provided: [ARBITRATION_MATERIALS]
- Decision authority: [DECISION_FINAL_AUTHORITY]
- Disagreement documentation: [CONFLICT_DOCUMENTATION]

Step 3: Team consultation
- Full team discussion: [TEAM_MEETING_PROCESS]
- Criteria refinement: [CRITERIA_MODIFICATION]
- Precedent setting: [PRECEDENT_DOCUMENTATION]

## 3. QUALITY ASSESSMENT FRAMEWORK

### 3.1 Quality Assessment Tool Selection

#### Tool Selection by Study Design

For Randomized Controlled Trials:
- Cochrane Risk of Bias Tool 2.0 (RoB 2)
  * Domains assessed: [ROB2_DOMAINS]
  * Signaling questions: [ROB2_QUESTIONS]
  * Algorithm application: [ROB2_ALGORITHM]

For Non-Randomized Studies:
- ROBINS-I (Risk Of Bias In Non-randomized Studies)
  * Bias domains: [ROBINS_DOMAINS]
  * Confounding assessment: [CONFOUNDING_APPROACH]
  * Classification criteria: [ROBINS_CLASSIFICATION]

For Cohort/Case-Control Studies:
- Newcastle-Ottawa Scale (NOS)
  * Selection assessment: [NOS_SELECTION]
  * Comparability assessment: [NOS_COMPARABILITY]
  * Outcome/Exposure assessment: [NOS_OUTCOME]
  * Quality scoring: [NOS_SCORING]

For Qualitative Studies:
- CASP Qualitative Checklist
  * Methodological rigor: [CASP_RIGOR]
  * Credibility: [CASP_CREDIBILITY]
  * Relevance: [CASP_RELEVANCE]

For Mixed Methods Studies:
- MMAT (Mixed Methods Appraisal Tool)
  * Qualitative component: [MMAT_QUALITATIVE]
  * Quantitative component: [MMAT_QUANTITATIVE]
  * Mixed integration: [MMAT_INTEGRATION]

### 3.2 Risk of Bias Assessment

#### Bias Domains by Study Type

For RCTs - Cochrane RoB 2 Domains:
1. Randomization Process
   - Random sequence generation: [RANDOMIZATION_ASSESSMENT]
   - Allocation concealment: [CONCEALMENT_ASSESSMENT]
   - Baseline differences: [BASELINE_ASSESSMENT]

2. Deviations from Intended Interventions
   - Blinding of participants/personnel: [BLINDING_ASSESSMENT]
   - Protocol adherence: [ADHERENCE_ASSESSMENT]
   - Appropriate analysis: [ANALYSIS_ASSESSMENT]

3. Missing Outcome Data
   - Attrition rates: [ATTRITION_ASSESSMENT]
   - Reasons for missingness: [MISSINGNESS_ASSESSMENT]
   - Impact on results: [IMPACT_ASSESSMENT]

4. Outcome Measurement
   - Blinding of outcome assessors: [ASSESSOR_BLINDING]
   - Measurement appropriateness: [MEASUREMENT_ASSESSMENT]
   - Measurement consistency: [CONSISTENCY_ASSESSMENT]

5. Selection of Reported Results
   - Selective reporting: [REPORTING_ASSESSMENT]
   - Protocol deviation: [PROTOCOL_COMPARISON]
   - Outcome switching: [OUTCOME_SWITCHING_CHECK]

Judgment criteria:
- Low risk: [LOW_RISK_DEFINITION]
- Some concerns: [MODERATE_RISK_DEFINITION]
- High risk: [HIGH_RISK_DEFINITION]

#### For Observational Studies - ROBINS-I Domains:
1. Confounding: [CONFOUNDING_EVALUATION]
2. Selection of participants: [SELECTION_EVALUATION]
3. Classification of interventions: [CLASSIFICATION_EVALUATION]
4. Deviations from intended interventions: [DEVIATION_EVALUATION]
5. Missing data: [MISSING_DATA_EVALUATION]
6. Measurement of outcomes: [OUTCOME_MEASUREMENT_EVALUATION]
7. Selection of reported result: [SELECTIVE_REPORTING_EVALUATION]

### 3.3 Overall Quality Determination

#### Quality Scoring System
Quality categories:
- High quality: [HIGH_QUALITY_CRITERIA]
  * Characteristics: [HIGH_QUALITY_FEATURES]
  * Required elements: [HIGH_QUALITY_REQUIREMENTS]

- Moderate quality: [MODERATE_QUALITY_CRITERIA]
  * Characteristics: [MODERATE_QUALITY_FEATURES]
  * Limitations: [MODERATE_QUALITY_LIMITATIONS]

- Low quality: [LOW_QUALITY_CRITERIA]
  * Characteristics: [LOW_QUALITY_FEATURES]
  * Serious limitations: [LOW_QUALITY_CONCERNS]

#### Quality-Based Decisions
Quality threshold application:
- Minimum inclusion threshold: [MINIMUM_THRESHOLD]
- Exclusion based on quality: [QUALITY_EXCLUSION_POLICY]
- Sensitivity analysis approach: [SENSITIVITY_BY_QUALITY]
- Quality weighting in synthesis: [QUALITY_WEIGHTING]

### 3.4 Quality Assessment Procedures

#### Dual Assessment Process
- Independent assessments: [DUAL_ASSESSMENT_PROPORTION]
- Disagreement resolution: [QUALITY_DISAGREEMENT_PROCESS]
- Consensus procedures: [QUALITY_CONSENSUS]

#### Documentation Requirements
- Detailed justifications: [JUSTIFICATION_STANDARD]
- Supporting evidence: [EVIDENCE_DOCUMENTATION]
- Decision trails: [DECISION_TRACKING]

## 4. DATA EXTRACTION FRAMEWORK

### 4.1 Extraction Form Development

#### Form Structure and Content

Study Identification Information:
- Citation details: [CITATION_FIELDS]
- Study ID: [ID_SYSTEM]
- Contact information: [CONTACT_FIELDS]
- Funding source: [FUNDING_DOCUMENTATION]
- Conflicts of interest: [COI_DOCUMENTATION]

Study Characteristics:
- Study design: [DESIGN_CLASSIFICATION]
- Study setting: [SETTING_DESCRIPTION]
- Country/region: [GEOGRAPHIC_DATA]
- Duration: [STUDY_DURATION]
- Sample size calculation: [POWER_CALCULATION]

Population Characteristics:
- Sample size: [N_TOTAL], [N_INTERVENTION], [N_CONTROL]
- Demographics:
  * Age: [AGE_DATA]
  * Gender: [GENDER_DISTRIBUTION]
  * Ethnicity/race: [ETHNICITY_DATA]
  * Socioeconomic status: [SES_INDICATORS]
- Inclusion/exclusion criteria used: [STUDY_CRITERIA]
- Baseline characteristics: [BASELINE_DATA]

Intervention/Exposure Details:
- Intervention name/description: [INTERVENTION_DESCRIPTION]
- Theoretical basis: [THEORETICAL_FOUNDATION]
- Components: [INTERVENTION_COMPONENTS]
- Delivery:
  * Mode: [DELIVERY_MODE]
  * Frequency: [FREQUENCY]
  * Duration: [DURATION]
  * Intensity: [INTENSITY]
- Provider: [PROVIDER_QUALIFICATIONS]
- Fidelity monitoring: [FIDELITY_MEASURES]
- Comparison condition: [COMPARISON_DESCRIPTION]

Outcome Data:
- Outcome measures: [OUTCOME_INSTRUMENTS]
- Measurement timing: [ASSESSMENT_TIMEPOINTS]
- Results data:
  * Continuous outcomes: [MEAN], [SD], [N]
  * Dichotomous outcomes: [EVENTS], [TOTAL]
  * Effect estimates: [EFFECT_SIZE], [CI], [P_VALUE]
- Subgroup analyses: [SUBGROUP_RESULTS]
- Adverse events: [AE_DATA]

### 4.2 Extraction Procedures

#### Extraction Pilot Testing
Pilot extraction:
- Pilot sample: [PILOT_EXTRACTION_SIZE]
- Diverse study types: [STUDY_TYPE_REPRESENTATION]
- Form refinement: [FORM_MODIFICATIONS]
- Extractor calibration: [CALIBRATION_PROCESS]

#### Dual Extraction Protocol
- Proportion dual extracted: [DUAL_EXTRACTION_PERCENTAGE]
- Independent extraction: [INDEPENDENCE_ASSURANCE]
- Comparison procedures: [COMPARISON_METHOD]
- Discrepancy resolution: [DISCREPANCY_PROCESS]

#### Data Verification and Quality Control
- Accuracy checking: [ACCURACY_PROCEDURES]
- Missing data identification: [MISSING_DATA_TRACKING]
- Author contact for clarification: [AUTHOR_CONTACT_PROTOCOL]
- Data entry verification: [ENTRY_VERIFICATION]
- Range and logic checks: [DATA_VALIDATION]

### 4.3 Missing Data Management

#### Identification of Missing Data
Categories of missing data:
- Missing studies: [PUBLICATION_BIAS_ASSESSMENT]
- Missing outcomes: [SELECTIVE_REPORTING_ASSESSMENT]
- Missing statistics: [STATISTICAL_DATA_GAPS]
- Insufficient reporting: [REPORTING_GAPS]

#### Strategies for Obtaining Missing Data
Author contact procedures:
- Contact attempt timeline: [CONTACT_SCHEDULE]
- Information requested: [DATA_REQUEST_SPECIFICS]
- Follow-up procedures: [FOLLOWUP_PROTOCOL]
- Documentation of responses: [RESPONSE_TRACKING]

Alternative data sources:
- Trial registries: [REGISTRY_CHECKING]
- Regulatory documents: [REGULATORY_SOURCES]
- Related publications: [COMPANION_PAPER_SEARCH]

#### Handling Unavailable Data
- Imputation methods: [IMPUTATION_APPROACH]
- Sensitivity analyses: [SENSITIVITY_HANDLING]
- Reporting of missing data: [MISSING_DATA_REPORTING]
- Impact on conclusions: [IMPACT_ASSESSMENT]

## 5. PRISMA FLOW DIAGRAM DOCUMENTATION

### 5.1 PRISMA 2020 Flow Diagram Structure

#### Identification Phase
Records identified from:
- Databases: [DATABASE_RESULTS]
  * Database 1: n = [N_DATABASE_1]
  * Database 2: n = [N_DATABASE_2]
  * Database 3: n = [N_DATABASE_3]
- Registers: [REGISTER_RESULTS]
- Other sources: [OTHER_SOURCE_RESULTS]

Records removed before screening:
- Duplicate records removed: n = [N_DUPLICATES]
- Records marked as ineligible: n = [N_AUTOMATED_EXCLUSIONS]
- Records removed for other reasons: n = [N_OTHER_REMOVED]

#### Screening Phase
Records screened:
- Title/abstract screening: n = [N_SCREENED]
- Records excluded: n = [N_EXCLUDED_SCREENING]

Reports sought for retrieval:
- Reports sought: n = [N_SOUGHT]
- Reports not retrieved: n = [N_NOT_RETRIEVED]

#### Eligibility Assessment Phase
Reports assessed for eligibility:
- Full-text assessed: n = [N_FULLTEXT_ASSESSED]
- Reports excluded: n = [N_EXCLUDED_FULLTEXT]

Exclusion reasons with counts:
- Reason 1: [EXCLUSION_REASON_1]: n = [N_REASON_1]
- Reason 2: [EXCLUSION_REASON_2]: n = [N_REASON_2]
- Reason 3: [EXCLUSION_REASON_3]: n = [N_REASON_3]
- Reason 4: [EXCLUSION_REASON_4]: n = [N_REASON_4]

#### Included Phase
Studies included in review:
- Qualitative synthesis: n = [N_QUALITATIVE_SYNTHESIS]
- Quantitative synthesis (meta-analysis): n = [N_QUANTITATIVE_SYNTHESIS]

Reports of included studies:
- Total reports: n = [N_INCLUDED_REPORTS]

### 5.2 Documentation Standards

#### Transparency Requirements
- Search date documentation: [SEARCH_DATES]
- Update search documentation: [UPDATE_DOCUMENTATION]
- Screening dates: [SCREENING_TIMELINE]
- Number of reviewers: [REVIEWER_COUNT]
- Software used: [SOFTWARE_DOCUMENTATION]

#### Supplementary Materials
- List of excluded studies: [EXCLUSION_LIST_LOCATION]
- Detailed exclusion reasons: [EXCLUSION_DETAILS]
- Inter-rater reliability data: [RELIABILITY_REPORTING]
- PRISMA checklist completion: [PRISMA_CHECKLIST]

## SELECTION PROCESS CHECKLIST

### Criteria Development
- [ ] Inclusion criteria clearly defined and justified
- [ ] Exclusion criteria clearly defined and justified
- [ ] PICO elements explicitly addressed
- [ ] Quality thresholds established
- [ ] Criteria pilot tested and refined
- [ ] Decision rules for ambiguous cases documented

### Screening Procedures
- [ ] De-duplication completed and documented
- [ ] Screening software selected and configured
- [ ] Reviewer training completed
- [ ] Pilot screening conducted with adequate agreement
- [ ] Title/abstract screening completed
- [ ] Full-text screening completed
- [ ] Disagreements resolved and documented

### Quality Assessment
- [ ] Appropriate quality assessment tools selected
- [ ] Quality assessment training completed
- [ ] Pilot quality assessment conducted
- [ ] Independent dual assessment completed
- [ ] Quality disagreements resolved
- [ ] Overall quality ratings assigned
- [ ] Quality-based decisions documented

### Data Extraction
- [ ] Extraction forms developed and pilot tested
- [ ] Extractor training completed
- [ ] Independent dual extraction completed (or proportion)
- [ ] Extraction discrepancies resolved
- [ ] Missing data identified and pursued
- [ ] Data verification completed
- [ ] Extraction database finalized

### Documentation
- [ ] PRISMA flow diagram completed
- [ ] All exclusions documented with reasons
- [ ] Inter-rater reliability reported
- [ ] Quality assessment results summarized
- [ ] Deviations from protocol documented
- [ ] Supplementary materials prepared

Ensure the selection process is:
- Systematic and transparent
- Reproducible with clear documentation
- Minimally biased through dual review
- Compliant with PRISMA standards
- Quality-focused with appropriate assessment
- Thoroughly documented at all stages
```

## Variables

### Research Context
- `[RESEARCH_TOPIC]`: Main research topic
- `[REVIEW_METHODOLOGY]`: Type of review
- `[MAIN_RESEARCH_QUESTION]`: Primary research question
- `[INITIAL_RECORDS_COUNT]`: Total records from searches

### Selection Criteria
- `[START_DATE]`: Beginning of date range
- `[END_DATE]`: End of date range
- `[ACCEPTABLE_STUDY_DESIGNS]`: Included study designs
- `[TARGET_POPULATION]`: Population of interest
- `[GEOGRAPHIC_LIMITS]`: Geographic restrictions
- `[LANGUAGE_CRITERIA]`: Language inclusion rules

### Population
- `[AGE_RANGE]`: Age inclusion criteria
- `[DEMOGRAPHIC_CHARACTERISTICS]`: Demographics
- `[HEALTH_STATUS_CRITERIA]`: Health status requirements
- `[SETTING_REQUIREMENTS]`: Setting criteria

### Interventions and Outcomes
- `[INTERVENTION_TYPES]`: Types of interventions
- `[PRIMARY_OUTCOME_1]`: First primary outcome
- `[PRIMARY_OUTCOME_2]`: Second primary outcome
- `[OUTCOME_1_DEFINITION]`: Definition of outcome 1

### Quality Assessment
- `[ROB2_DOMAINS]`: Risk of Bias 2 domains
- `[ROBINS_DOMAINS]`: ROBINS-I domains
- `[HIGH_QUALITY_CRITERIA]`: High quality definition
- `[MINIMUM_THRESHOLD]`: Minimum quality threshold

### PRISMA Data
- `[N_DATABASE_1]`: Results from database 1
- `[N_DUPLICATES]`: Number of duplicates removed
- `[N_SCREENED]`: Records screened
- `[N_EXCLUDED_SCREENING]`: Excluded at screening
- `[N_FULLTEXT_ASSESSED]`: Full texts assessed
- `[N_QUALITATIVE_SYNTHESIS]`: Studies in qualitative synthesis
- `[N_QUANTITATIVE_SYNTHESIS]`: Studies in meta-analysis

## Usage Examples

### Example 1: Clinical RCT Screening
"Develop a screening protocol for RCTs of cognitive behavioral therapy for depression in adults. Use Cochrane RoB 2 for quality assessment. Include studies with validated depression outcome measures and minimum 3-month follow-up. Expect ~3,000 initial records."

### Example 2: Mixed Methods Educational Research
"Create a selection protocol for mixed methods research on online learning effectiveness in higher education. Use MMAT for quality assessment. Include diverse study designs published 2015-2024. Screen approximately 1,500 records with two independent reviewers."

### Example 3: Observational Health Services Research
"Design a screening process for cohort studies examining health disparities in chronic disease management. Use Newcastle-Ottawa Scale and ROBINS-I. Include studies with adequate confounding control and minimum 1-year follow-up."

## Best Practices

1. **Liberal screening, conservative inclusion** - Include borderline studies at title/abstract stage
2. **Dual independent review** - Use two reviewers for objectivity and reliability
3. **Pilot before full screening** - Test criteria and achieve adequate agreement
4. **Document everything** - Record all decisions and reasons for transparency
5. **Use validated tools** - Apply established quality assessment instruments
6. **Plan for disagreements** - Establish clear resolution procedures
7. **Track inter-rater reliability** - Calculate and report agreement statistics
8. **Maintain PRISMA compliance** - Follow reporting standards throughout
9. **Contact authors proactively** - Seek missing information systematically
10. **Build in quality checks** - Verify data accuracy at multiple points

## Tips for Success

- Use screening software (Covidence, DistillerSR, Rayyan) for efficiency
- Establish clear decision rules before screening begins
- Schedule regular team meetings to discuss challenging cases
- Maintain detailed logs of all screening decisions
- Calculate kappa statistics for inter-rater agreement (target κ ≥ 0.6-0.8)
- Be consistent in applying criteria across all studies
- Default to inclusion when uncertain during early stages
- Keep original search results as backup
- Version control extraction forms and databases
- Allow adequate time (typically 8-12 weeks for screening and quality assessment)
