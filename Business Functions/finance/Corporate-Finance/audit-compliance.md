---
category: finance
title: Audit & Compliance Readiness Assessment
tags:
- internal-audit
- regulatory-compliance
- internal-controls
- sox-compliance
- readiness-assessment
use_cases:
- Assessing readiness to stand up or mature an internal audit and compliance program
- Identifying gaps in control design/testing, evidence, and issue remediation
- Producing an audit plan, control testing approach, and board-ready reporting package
related_templates:
- finance/Risk-Management/enterprise-risk-management.md
- legal-compliance/compliance-programs.md
- strategy/okr-implementation-framework.md
industries:
- education
- finance
- government
- healthcare
- manufacturing
- technology
type: framework
difficulty: intermediate
slug: audit-compliance-readiness-assessment
---

# Audit & Compliance Readiness Assessment

## Purpose
Assess readiness to operate an audit and compliance program across six dimensions: Governance & Independence, Scope & Regulatory Mapping, Risk Assessment & Planning, Controls & Testing, Issues & Remediation, and Reporting & Continuous Monitoring. Identify gaps and produce a practical operating plan.

## Template

Conduct an audit & compliance readiness assessment for {ORGANIZATION} operating under {REGULATIONS_AND_FRAMEWORKS}.

Assess readiness across six dimensions, scoring each 1–5:

**1. GOVERNANCE & INDEPENDENCE READINESS**
- Audit committee/board oversight is defined (charter, cadence, escalation)
- Internal audit independence is established (reporting line, access, authority)
- Three lines of defense roles are explicit and enforced
- Decision rights exist (who approves scope changes and exceptions)
- Resourcing model is defined (in-house vs co-source vs outsource)

**2. SCOPE & REGULATORY MAPPING READINESS**
- Regulatory inventory is current and owned (what applies and why)
- Obligations are mapped to processes, systems, and control owners
- In-scope entities, locations, and third parties are defined
- IT and data domains are explicitly included (access, change, privacy/security)
- Evidence requirements are known (what “good” looks like for auditors/regulators)

**3. RISK ASSESSMENT & AUDIT PLANNING READINESS**
- Risk assessment methodology exists (inherent/residual risk, materiality)
- Audit universe is defined (processes, systems, locations, vendors)
- Annual plan is risk-based with clear coverage and frequency
- Regulatory exam/audit coordination is planned (timelines, dependencies)
- Flex capacity exists for emerging risks and incidents

**4. CONTROLS, TESTING & EVIDENCE READINESS**
- Key controls are defined and documented (design, frequency, owner)
- Testing approach is standardized (sampling, walkthroughs, re-performance)
- Evidence standards are clear (what to capture, where, retention)
- ITGCs and application controls are tested consistently (access, change, ops)
- QA/review exists to ensure workpaper quality and defensibility

**5. ISSUES, REMEDIATION & ASSURANCE READINESS**
- Findings are classified (severity, impact, likelihood) with consistent criteria
- Remediation workflow exists (owner, due date, interim controls, validation)
- Root cause analysis is performed and recorded
- Re-testing and closure criteria are defined and enforced
- Independent assurance exists (audit/compliance validation, second-line challenge)

**6. REPORTING & CONTINUOUS MONITORING READINESS**
- Board/executive reporting is action-oriented (decisions, owners, next steps)
- Dashboards include KRIs/KCIs and trend views (exceptions, aging, coverage)
- Continuous monitoring exists for high-risk areas (where feasible)
- Documentation is audit-ready (traceable inputs, approvals, and evidence)
- Lessons learned feed playbooks and control improvements

Deliver your assessment as:

1. **EXECUTIVE SUMMARY** - Overall score, maturity level, top 3 risks
2. **DIMENSION SCORECARD** - Table with score (X.X/5) and key finding per dimension
3. **SCOPE MAP** - Regulations → obligations → processes/systems → owners
4. **TESTING APPROACH** - What is tested, how often, and how evidence is stored
5. **ISSUE LOG SUMMARY** - Top issues, owners, aging, and remediation status
6. **90-DAY PLAN** - Stabilization actions and success metrics

Use this maturity scale:
- 1.0-1.9: Initial (ad-hoc testing; weak evidence and follow-through)
- 2.0-2.9: Developing (basic program; inconsistent coverage and standards)
- 3.0-3.9: Defined (repeatable cycle; manageable gaps)
- 4.0-4.9: Managed (disciplined testing and closure; actionable reporting)
- 5.0: Optimized (continuous monitoring; strong risk outcomes)

## Variables

| Variable | Description | Example |
|----------|-------------|---------|
| `[ORGANIZATION]` | Organization name | "HealthTech Solutions" |
| `[INDUSTRY]` | Industry | "Healthcare technology" |
| `[REGULATIONS/FRAMEWORKS]` | Applicable regulations/frameworks | "SOX, HIPAA" |
| `[SCOPE]` | Scope summary | "Financial reporting + privacy" |
| `[CADENCE]` | Audit cadence | "Quarterly testing" |

## Example

**SOX + Privacy Program - Readiness**

> Assess audit & compliance readiness for **HealthTech Solutions** subject to **SOX and HIPAA**. Governance exists but independence and escalation are unclear; scope mapping to systems and control owners is incomplete; risk-based planning exists but coverage and timing need tightening; control testing is inconsistent and evidence retention is weak; issues are tracked but root cause and re-testing discipline is lacking; reporting is frequent but not action-oriented. Provide a scorecard and a 90-day stabilization checklist.

