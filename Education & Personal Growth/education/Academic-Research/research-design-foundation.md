---
category: education
related_templates:
- education/Academic-Research/research-design-sampling-data.md
- education/Academic-Research/research-design-analysis-quality.md
- education/Academic-Research/research-design-overview.md
tags:
- theoretical-framework
- research-paradigms
- conceptual-models
- epistemology
- design-readiness
- research-foundation
title: Research Design Foundation Readiness Assessment
use_cases:
- Evaluating readiness to finalize a theoretical foundation and study design
- Identifying gaps in paradigm alignment, conceptual clarity, and design justification
- Reducing rework before proposals, IRB submission, or preregistration
- Producing a defensible rationale that reviewers can follow
industries:
- education
- healthcare
type: framework
difficulty: intermediate
slug: research-design-foundation
---

# Research Design Foundation Readiness Assessment

## Purpose
Comprehensively assess readiness to lock the foundational decisions for a research study across six dimensions: Problem & Contribution Clarity, Theory & Conceptual Model Fit, Paradigm & Assumptions Coherence, Question & Construct Precision, Design & Method Fit, and Feasibility & Alignment. This framework helps you prevent “design drift,” strengthen justification, and produce a foundation that holds up under committee or peer review.

## Template

Conduct a comprehensive research design foundation readiness assessment for {STUDY_CONTEXT} pursuing {RESEARCH_GOALS} under {CONSTRAINTS}.

Assess readiness across six dimensions, scoring each 1–5:

**1. PROBLEM & CONTRIBUTION CLARITY READINESS**
Evaluate whether the study has a compelling reason to exist by assessing whether the problem is scoped to a specific context and audience, whether the literature gap is concrete rather than vague, and whether the contribution is stated as precise claims about what new knowledge will be produced. Examine whether the study avoids overpromising, differentiates novelty from mere new data, and identifies what the work will change in theory, practice, or decision-making if it succeeds.

**2. THEORY & CONCEPTUAL MODEL FIT READINESS**
Evaluate whether the theoretical foundation is doing real explanatory work by assessing whether the chosen theory fits the phenomenon, defines constructs with discipline-appropriate precision, and offers testable or traceable mechanisms. Examine whether the conceptual model clarifies relationships, boundary conditions, and alternative explanations, and whether the framework is parsimonious enough to guide design decisions without turning into an exhaustive literature summary.

**3. PARADIGM & ASSUMPTIONS COHERENCE READINESS**
Evaluate whether the philosophical stance is coherent by assessing whether epistemological assumptions match the type of claims you intend to make and whether ontological assumptions align with how you treat constructs as measurable, interpretive, or mixed. Examine whether values and positionality are acknowledged where relevant, whether quality criteria match the paradigm (e.g., validity vs trustworthiness), and whether the paradigm choice informs method selection rather than appearing as a decorative paragraph.

**4. QUESTION & CONSTRUCT PRECISION READINESS**
Evaluate whether questions can be answered cleanly by assessing whether primary and secondary research questions are unambiguous, whether constructs are operationalized (or interpretable) with clear inclusion/exclusion boundaries, and whether hypotheses or propositions are stated with appropriate conditionality. Examine whether outcomes, mechanisms, contexts, and comparisons (where relevant) are specified, and whether the scope is narrow enough to be feasible while still significant.

**5. DESIGN & METHOD FIT READINESS**
Evaluate whether the design can credibly support the intended inference by assessing whether the design type (experimental, quasi-experimental, observational, case study, phenomenological, grounded theory, mixed methods) matches the question and constraints. Examine whether bias threats are anticipated, whether the sampling logic makes sense for the inference goal, whether measurement choices are justified, and whether the chosen approach can distinguish signal from noise in a way reviewers will accept.

**6. FEASIBILITY & ALIGNMENT READINESS**
Evaluate whether the foundation translates into an executable plan by assessing access to participants/sites/data, timeline realism, required skills and tooling, and alignment with ethics and institutional constraints. Examine whether the plan has a minimum viable path if access or recruitment underperforms, whether dependencies are identified (permissions, training, instruments), and whether the study’s ambition is calibrated to resources without sacrificing rigor.

---

## Required Output Format

Structure your assessment as:

1. **EXECUTIVE SUMMARY** - Overall readiness score (X.X/5.0), maturity level, “ready to lock” recommendation, top 3 foundation risks

2. **DIMENSION SCORECARD** - Table with dimension, score (X.X/5), key gap, and the single most important improvement

3. **FOUNDATION STATEMENT (1 PAGE)** - Problem, contribution, theory, questions, and design in a tight narrative that could go into a proposal

4. **CONCEPTUAL MODEL NOTES** - Construct definitions, hypothesized relationships/mechanisms, boundary conditions, and key alternative explanations

5. **DESIGN JUSTIFICATION OUTLINE** - Why this paradigm and design are the best fit given {CONSTRAINTS}, including bias threats and mitigations

6. **NEXT STEPS (2–4 WEEKS)** - A short plan to finalize what’s missing before proposal/IRB/preregistration

Use this maturity scale:
- **1.0–1.9: Fragmented** (unclear problem/theory/questions; design decisions unstable)
- **2.0–2.9: Emerging** (basic foundation exists; significant alignment and feasibility gaps)
- **3.0–3.9: Coherent** (solid foundation; targeted refinements needed to lock)
- **4.0–4.9: Proposal-ready** (well-justified, aligned, and feasible foundation)
- **5.0: Exemplary** (field-leading clarity and coherence; minimal reviewer friction)

---

## Variables

| Variable | Description | Example |
|----------|-------------|---------|
| `{STUDY_CONTEXT}` | What study you’re designing (topic + population + setting) | "Phenomenological study of nurse burnout in rural community hospitals" |
| `{RESEARCH_GOALS}` | The main aims and claims the study intends to support | "Explain drivers and lived experience of burnout; propose actionable mechanisms" |
| `{CONSTRAINTS}` | The key feasibility and institutional constraints | "12-month timeline, limited site access, ethics sensitivity, small budget" |

---

## Usage Example

**Input:**
"{STUDY_CONTEXT}: Quasi-experimental evaluation of a new tutoring program in first-year calculus"
"{RESEARCH_GOALS}: Estimate impact on pass rates and understand who benefits most"
"{CONSTRAINTS}: No randomization permitted; administrative data only; 9-month timeline"

**Output (abridged):**
- Overall Readiness: **2.9/5.0 (Emerging)**
- Recommendation: **READY WITH REVISIONS** (lock foundation after clarifying estimand, comparators, and mechanism story)
- Top Risks: contribution not clearly differentiated from prior interventions, conceptual model missing boundary conditions, design threats (selection bias) not fully mitigated

Dimension Scorecard:
- Problem & Contribution: 2.8/5 (state novelty vs existing tutoring studies; clarify what “impact” means)
- Theory & Model: 2.6/5 (define mechanism hypotheses: time-on-task, self-efficacy; add boundary conditions)
- Paradigm & Assumptions: 3.2/5 (post-positivist stance fits; specify what counts as causal evidence)
- Questions & Constructs: 3.0/5 (define primary estimand and subgroup rules)
- Design & Method Fit: 2.7/5 (specify matching strategy + sensitivity checks)
- Feasibility & Alignment: 3.1/5 (data access confirmed; timeline feasible if scope bounded)

Next 3 weeks:
- Week 1: Write 1-page foundation statement + conceptual model diagram.
- Week 2: Specify estimand, inclusion/exclusion, comparison group strategy, and bias mitigations.
- Week 3: Align measures and available administrative variables; finalize proposal-ready narrative.

---

## Related Resources

- **[Research Design - Sampling & Data](research-design-sampling-data.md)** - Converts foundation decisions into sampling, recruitment, and measurement plans
- **[Research Analysis & Quality Assurance Readiness Assessment](research-design-analysis-quality.md)** - Aligns analysis rigor, QA thresholds, and reproducibility expectations
- **[Research Design - Overview](research-design-overview.md)** - Integrates the full research design workflow across modules
