---
category: education
title: Academic Grant Writing Readiness Assessment
tags:
- grant-writing
- research-funding
- funding-proposals
- budget-justification
- readiness-assessment
use_cases:
- Determining whether a project is ready to pursue a specific funding opportunity
- Identifying proposal gaps before committing writing time and institutional effort
- Producing a defensible outline, compliance checklist, and submission plan
- Aligning PI, co-investigators, and research administration on scope and feasibility
related_templates:
- education/Academic-Research/research-design.md
- education/Academic-Research/publication-writing.md
- education/Academic-Research/research-design-impact.md
- education/curriculum-development.md
- education/curriculum-development-framework.md
industries:
- education
- government
- healthcare
type: framework
difficulty: intermediate
slug: academic-grant-writing
---

# Academic Grant Writing Readiness Assessment

## Purpose
Assess whether you’re ready to pursue and submit a competitive grant proposal by scoring six dimensions: Opportunity Fit, Project Clarity, Methods & Feasibility, Budget & Resources, Compliance & Risk, and Submission Workflow. Use the output to decide **go / revise-first / no-go**, and to generate a focused writing plan.

## Template

Conduct a grant writing readiness assessment for {FUNDING_CONTEXT} supporting {PROJECT_SUMMARY} under {SPONSOR_REQUIREMENTS}.

Assess readiness across six dimensions, scoring each 1–5:

**1. OPPORTUNITY FIT READINESS**
Evaluate whether the funding opportunity is the right match by assessing sponsor priorities, eligibility, competitiveness, and the degree of alignment between what you can credibly deliver and what the sponsor values. Identify “fit risks” (misaligned scope, wrong mechanism, wrong audience, weak track record) and mitigation options (re-scoping, teaming, alternative mechanism).

**2. PROJECT CLARITY & SIGNIFICANCE READINESS**
Evaluate whether the proposal’s core story is crisp: the problem/gap, why it matters now, the contribution, and who benefits. Confirm that aims are specific and measurable, success criteria are explicit, and the narrative is coherent across sections (aims ↔ methods ↔ outcomes ↔ impact).

**3. METHODS & FEASIBILITY READINESS**
Evaluate whether the proposed approach is defensible and doable: design choices match aims, milestones are realistic, and dependencies are identified (data access, partnerships, equipment, recruitment, governance). Identify feasibility risks (access delays, sample constraints, technical uncertainty) and specify contingency plans.

**4. BUDGET & RESOURCES READINESS**
Evaluate whether the budget matches the work: key cost drivers are justified, roles and effort are coherent, and institutional resources (facilities, computing, staff support) are available. Confirm that the requested amount aligns with sponsor norms and that “must-have vs nice-to-have” spend is clear.

**5. COMPLIANCE & RISK READINESS**
Evaluate whether you can submit and execute responsibly by assessing regulatory and policy constraints (human subjects/IRB, privacy, data sharing, export controls, conflicts of interest, biosafety, animal use, subawards). Identify compliance gating items and the path to completion before award start.

**6. SUBMISSION WORKFLOW READINESS**
Evaluate whether you can ship on time: roles (PI, co-Is, grants office), timeline, internal deadlines, document ownership, and review cycles are defined. Confirm that you have a plan for required attachments (biosketches, letters, facilities, data management plan), and for final validation against sponsor rules.

---

## Required Output Format

1. **EXECUTIVE SUMMARY** - Overall readiness score (X.X/5.0), maturity level, go/revise-first/no-go, top 3 risks

2. **DIMENSION SCORECARD** - Table: dimension, score (1–5), evidence, biggest gap, highest-impact fix

3. **GAP LIST (TOP 5)** - Ranked by impact × urgency, with concrete next actions and owners

4. **SUBMISSION PLAN**
- Timeline (week-by-week to deadline)
- Workstream owners (science narrative, methods, budget, compliance, attachments)
- Review plan (internal reviewers + revision gates)

5. **ONE-PAGE PROPOSAL OUTLINE**
- Title + 1–2 sentence summary
- Aims (3–5 bullets)
- Innovation / significance
- Approach (high-level)
- Expected outputs + impact

---

## Maturity Scale (1–5)
- **1 — Initial:** Opportunity unclear; aims/methods/budget not coherent; high compliance uncertainty.
- **2 — Developing:** Basic fit and concept exist; major gaps in feasibility, budget alignment, or compliance.
- **3 — Defined:** Solid narrative and plan; manageable risks; needs tightening, evidence, and review readiness.
- **4 — Managed:** Strong fit; well-justified scope/budget; compliance path clear; submission process reliable.
- **5 — Optimized:** Highly competitive package; reusable proposal assets; efficient workflows; strong reviewer anticipation.

---

## Variables (Use Max 3)

| Variable | What to include | Example |
|---|---|---|
| `{FUNDING_CONTEXT}` | Funder, mechanism/program, deadline, budget cap, eligibility, review criteria | “NSF CAREER, deadline Aug 1, $500k/5y, early-career PI” |
| `{PROJECT_SUMMARY}` | 2–4 sentences: problem, aims, approach, outcomes | “Develop X to improve Y via Z; deliver dataset + toolkit + evaluation” |
| `{SPONSOR_REQUIREMENTS}` | The must-follow rules and expected sections/attachments | “Data management plan required; 15 pages; broader impacts; letters” |

---

## Example (Filled)

**Input**
- `{FUNDING_CONTEXT}`: “NIH R21, due in 7 weeks, $275k/2y, clinical data + ML methods.”
- `{PROJECT_SUMMARY}`: “Build and validate a risk model for post-op complications using EHR + notes; deliver open evaluation protocol and clinical deployment plan.”
- `{SPONSOR_REQUIREMENTS}`: “Human subjects likely; data sharing plan required; page limits; biosketches; budget justification.”

**Output (abridged)**
- Executive summary: 3.1/5 (Defined), **revise-first**
- Top risks: (1) IRB + data use agreement timeline, (2) insufficient preliminary evidence, (3) unclear clinical workflow integration
- Highest-impact fixes (next 10 days): finalize data access path + governance; add pilot analysis + effect size expectations; align aims to R21 innovation framing; draft budget with 2 tiers

---

## Best Practices (8)

1. Write to the sponsor’s scoring criteria (mirror headings and language).
2. Make the “so what” explicit in the first page and in every aim.
3. Keep aims testable and independent enough to survive partial failure.
4. Justify feasibility with concrete evidence (pilot results, access letters, timelines).
5. Tie budget line items to specific work packages and deliverables.
6. Surface compliance early; treat it as a schedule constraint, not an afterthought.
7. Use ruthless revision cycles: clarity pass, logic pass, compliance pass, polish pass.
8. Pre-empt reviewer objections (limitations + mitigations) without undermining confidence.

---

## Related Resources
- Use the Research Design suite to firm up study logic and feasibility: `research-design.md`
- Use the Impact module to strengthen broader impacts and dissemination: `research-design-impact.md`
- Use the Publication template to align writing style and reporting norms: `publication-writing.md`
