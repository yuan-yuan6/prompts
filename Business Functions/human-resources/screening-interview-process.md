---
category: human-resources
related_templates:
- human-resources/candidate-assessment-selection.md
- human-resources/job-analysis-definition.md
- human-resources/recruitment-metrics-optimization.md
tags:
- structured-interviews
- candidate-screening
- interview-scorecards
- hiring-process
- readiness-assessment
title: Screening & Interview Process Readiness Assessment
use_cases:
- Designing structured interview processes
- Creating screening criteria and evaluation frameworks
- Developing interview question banks and scorecards
industries:
- education
- finance
- healthcare
- manufacturing
- retail
- technology
type: framework
difficulty: intermediate
slug: screening-interview-process
---

# Screening & Interview Process Readiness Assessment

## Purpose
Assess readiness to run a screening and interview process that is structured, fair, efficient, and predictive of on-the-job success.

## Quick Assessment Prompt

> Assess interview process readiness for [ROLE_FAMILY] across [INTERVIEW_STAGES] stages. Score readiness (1–5) across: (1) Role criteria & rubrics, (2) Interview design & questions, (3) Interviewer capability & calibration, (4) Candidate experience & logistics, (5) Decisioning & documentation, (6) Measurement & iteration. Provide a scorecard, top gaps, and a 60-day plan.

## Readiness Scorecard (1–5)

### 1) Role Criteria & Rubrics
- 1 — Initial: Criteria unclear; interviewers evaluate different things.
- 3 — Defined: Rubrics and scoring guidance; competencies defined.
- 5 — Optimized: Rubrics are validated and refined using outcomes.

### 2) Interview Design & Questions
- 1 — Initial: Questions are ad-hoc; overlap and gaps across stages.
- 3 — Defined: Interview plan with question bank; coverage by competency.
- 5 — Optimized: Design is optimized for signal and speed; duplication removed.

### 3) Interviewer Capability & Calibration
- 1 — Initial: Interviewers are untrained; inconsistent scoring.
- 3 — Defined: Training and calibration; shadowing and feedback loops.
- 5 — Optimized: Calibration is continuous; signal quality is consistent across interviewers.

### 4) Candidate Experience & Logistics
- 1 — Initial: Scheduling is slow; communication inconsistent.
- 3 — Defined: Standard communications; scheduling SLAs; accessibility considered.
- 5 — Optimized: Candidate experience is measurable and continuously improved.

### 5) Decisioning & Documentation
- 1 — Initial: Debriefs unstructured; decisions slow and subjective.
- 3 — Defined: Debrief format; decision rules; documented evidence.
- 5 — Optimized: Decisions are fast and auditable; hiring quality improves.

### 6) Measurement & Iteration
- 1 — Initial: No tracking of conversion or drop-off drivers.
- 3 — Defined: KPIs tracked; retrospectives; improvements prioritized.
- 5 — Optimized: Iteration loop improves speed and quality; learnings are captured.

## Deliverables
- Interview readiness scorecard and gap list
- Interview plan (stages, competencies, question coverage)
- Rubrics and debrief templates
- Interviewer training and calibration plan
- Candidate experience standards and KPI dashboard

## Maturity Scale
- 1.0–1.9: Initial (ad-hoc, minimal capabilities)
- 2.0–2.9: Developing (some capabilities, significant gaps)
- 3.0–3.9: Defined (solid foundation, scaling challenges)
- 4.0–4.9: Managed (mature capabilities, optimization focus)
- 5.0: Optimized (industry-leading, continuous improvement)

## Variables
- [ROLE_FAMILY]: Role family
- [INTERVIEW_STAGES]: Number of stages
- [COMPETENCIES]: Competencies
- [SLA_DAYS]: Scheduling/feedback SLAs
- [CANDIDATE_NPS]: Candidate experience metric
- [PASS_THROUGH]: Stage conversion rates

## Example (Condensed)
- Hiring: Product roles with slow scheduling and inconsistent evaluations
- Scores (1–5): Criteria 3; Design 2; Calibration 2; Experience 2; Decisions 2; Iteration 2
- 60-day priorities: Standardize plan + rubrics; train interviewers; implement SLAs and stage conversion tracking

