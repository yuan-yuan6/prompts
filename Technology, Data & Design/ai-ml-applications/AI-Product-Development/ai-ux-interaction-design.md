---
category: ai-ml-applications
title: AI UX & Interaction Design Readiness Assessment
tags:
- ai-ux-design
- ai-interaction
- ai-transparency
- human-ai-interaction
- readiness-assessment
use_cases:
- Designing user experiences for AI-powered features
- Creating interaction patterns for AI systems
- Handling AI uncertainty and errors gracefully
- Building trust and transparency in AI products
related_templates:
- ai-ml-applications/AI-Product-Development/ai-feature-development.md
- ai-ml-applications/LLM-Applications/conversational-ai-chatbots.md
industries:
- technology
- finance
- healthcare
- retail
- manufacturing
type: framework
difficulty: intermediate
slug: ai-ux-interaction-design
---

# AI UX & Interaction Design Readiness Assessment

## Purpose
Assess readiness to design AI-driven user experiences that are trustworthy, transparent, and aligned to real workflows, including safety and feedback loops.

## Quick Prompt

> Assess AI UX readiness for [PRODUCT] feature [FEATURE]. Score readiness (1–5) across: (1) Workflow understanding, (2) Interaction patterns, (3) Trust & transparency, (4) Error handling & escalation, (5) Safety & content policy, (6) Measurement & iteration. Provide a scorecard and a 60-day design plan.

## Readiness Scorecard (1–5)

### 1) Workflow Understanding
- 1 — Initial: Design based on assumptions; limited user research.
- 3 — Defined: Workflows documented with user research and task analysis.
- 5 — Optimized: Workflow insights drive continuous UX improvements.

### 2) Interaction Patterns
- 1 — Initial: Patterns inconsistent; unclear affordances.
- 3 — Defined: Consistent patterns for suggestions, edits, and automation.
- 5 — Optimized: Patterns are optimized for speed and clarity across the product.

### 3) Trust & Transparency
- 1 — Initial: Users can’t tell what the AI did or why.
- 3 — Defined: Disclosures, citations, and confidence cues defined.
- 5 — Optimized: Trust is measured and improved; transparency reduces errors.

### 4) Error Handling & Escalation
- 1 — Initial: No clear recovery paths; failures confuse users.
- 3 — Defined: Fallback behaviors and escalation to humans/systems defined.
- 5 — Optimized: Resilient UX supports recovery and prevents cascading failures.

### 5) Safety & Content Policy
- 1 — Initial: No safety policy; harmful outputs possible.
- 3 — Defined: Content policy, guardrails, and edge cases documented.
- 5 — Optimized: Safety is monitored; policies evolve with usage.

### 6) Measurement & Iteration
- 1 — Initial: No instrumentation; no feedback loop.
- 3 — Defined: Telemetry and feedback collection; design iteration cadence.
- 5 — Optimized: Iteration loop improves task success and reduces errors over time.

## Deliverables
- AI UX readiness scorecard and top design risks
- Workflow map and interaction pattern library
- Trust and transparency requirements
- Fallback and escalation UX specification
- Measurement plan (task success, satisfaction, error rates)

## Maturity Scale
- 1.0–1.9: Initial (ad-hoc, minimal capabilities)
- 2.0–2.9: Developing (some capabilities, significant gaps)
- 3.0–3.9: Defined (solid foundation, scaling challenges)
- 4.0–4.9: Managed (mature capabilities, optimization focus)
- 5.0: Optimized (industry-leading, continuous improvement)

## Variables
- [PRODUCT]: Product name
- [FEATURE]: Feature name
- [USER_PERSONAS]: User personas
- [TASK_SUCCESS]: Task success definition
- [DISCLOSURES]: Disclosure requirements
- [ESCALATION_PATH]: Escalation path

## Example (Condensed)
- Feature: AI drafting assistant for customer emails
- Scores (1–5): Workflow 3; Patterns 2; Trust 2; Recovery 2; Safety 3; Iteration 2
- 60-day priorities: Standardize interaction patterns; add transparency and fallback UX; instrument task success and error rates

